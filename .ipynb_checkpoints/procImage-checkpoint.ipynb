{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "textdetection.py\n",
      "       A demo script of the Extremal Region Filter algorithm described in:\n",
      "       Neumann L., Matas J.: Real-Time Scene Text Localization and Recognition, CVPR 2012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "print('\\ntextdetection.py')\n",
    "print('       A demo script of the Extremal Region Filter algorithm described in:')\n",
    "print('       Neumann L., Matas J.: Real-Time Scene Text Localization and Recognition, CVPR 2012\\n')\n",
    "path_to_image_to_be_processed = '/home/pboord/Downloads/yelp/waitrose.jpg'\n",
    "pathname = os.path.dirname(sys.argv[0])\n",
    "img      = cv2.imread(path_to_image_to_be_processed)\n",
    "# for visualization\n",
    "vis      = img.copy()\n",
    "print cv2.__version__\n",
    "# Extract channels to be processed individually\n",
    "channels = cv2.text.computeNMChannels(img)\n",
    "# Append negative channels to detect ER- (bright regions over dark background)\n",
    "cn = len(channels)-1\n",
    "for c in range(0,cn):\n",
    "  channels.append((255-channels[c]))\n",
    "# Apply the default cascade classifier to each independent channel (could be done in parallel)\n",
    "print(\"Extracting Class Specific Extremal Regions from \"+str(len(channels))+\" channels ...\")\n",
    "print(\"    (...) this may take a while (...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Class Specific Extremal Regions from 9 channels ...\n",
      "    (...) this may take a while (...)\n"
     ]
    }
   ],
   "source": [
    "for channel in channels:\n",
    "\n",
    "  erc1 = cv2.text.loadClassifierNM1(pathname+'/trained_classifierNM1.xml')\n",
    "  er1 = cv2.text.createERFilterNM1(erc1,16,0.00015,0.13,0.2,True,0.1)\n",
    "\n",
    "  erc2 = cv2.text.loadClassifierNM2(pathname+'/trained_classifierNM2.xml')\n",
    "  er2 = cv2.text.createERFilterNM2(erc2,0.5)\n",
    "\n",
    "  regions = cv2.text.detectRegions(channel,er1,er2)\n",
    "\n",
    "  rects = cv2.text.erGrouping(img,channel,[r.tolist() for r in regions])\n",
    "  #rects = cv2.text.erGrouping(img,gray,[x.tolist() for x in regions], cv2.text.ERGROUPING_ORIENTATION_ANY,'../../GSoC2014/opencv_contrib/modules/text/samples/trained_classifier_erGrouping.xml',0.5)\n",
    "\n",
    "  #Visualization\n",
    "  for r in range(0,np.shape(rects)[0]):\n",
    "    rect = rects[r]\n",
    "    cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (0, 0, 0), 2)\n",
    "    cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (255, 255, 255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Visualization\n",
    "cv2.imshow(\"Text detection result\", vis)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
