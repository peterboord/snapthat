{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import cv2\n",
    "#print('\\ntextdetection.py')\n",
    "#print('       A demo script of the Extremal Region Filter algorithm described in:')\n",
    "#print('       Neumann L., Matas J.: Real-Time Scene Text Localization and Recognition, CVPR 2012\\n')\n",
    "path_to_image_to_be_processed = '/home/pboord/Downloads/yelp/waitrose.jpg'\n",
    "#pathname = os.path.dirname(sys.argv[0])\n",
    "pathname = '/home/pboord/Downloads/yelp'\n",
    "img      = cv2.imread(path_to_image_to_be_processed)\n",
    "# for visualization\n",
    "vis      = img.copy()\n",
    "#print cv2.__version__\n",
    "# Extract channels to be processed individually\n",
    "channels = cv2.text.computeNMChannels(img)\n",
    "# Append negative channels to detect ER- (bright regions over dark background)\n",
    "cn = len(channels)-1\n",
    "for c in range(0,cn):\n",
    "  channels.append((255-channels[c]))\n",
    "# Apply the default cascade classifier to each independent channel (could be done in parallel)\n",
    "#print(\"Extracting Class Specific Extremal Regions from \"+str(len(channels))+\" channels ...\")\n",
    "#print(\"    (...) this may take a while (...)\")\n",
    "def overlap(b1, b2):\n",
    "    return (b1[0] <= b2[0]+b2[2]) and (b1[0]+b1[2] >= b2[0]) and (b1[1] <= b2[1]+b2[3]) and (b1[1]+b1[3] >= b2[1])\n",
    "def bigrect(b1, b2):\n",
    "    b0 = b1\n",
    "    b0[0]=min(b1[0],b2[0])\n",
    "    b0[1]=min(b1[1],b2[1])\n",
    "    b0[2]=max(b1[0]+b1[2],b2[0]+b2[2]) - b0[0]\n",
    "    b0[3]=max(b1[1]+b1[3],b2[1]+b2[3]) - b0[1]\n",
    "    return b0\n",
    "def lbwh2lbrt(b):\n",
    "    b0=b\n",
    "    b0[0]=b[0]\n",
    "    b0[1]=b[1]\n",
    "    b0[2]=b[0]+b[2]\n",
    "    b0[3]=b[1]+b[3]\n",
    "    return b0\n",
    "b = []\n",
    "for channel in channels:\n",
    "\n",
    "  erc1 = cv2.text.loadClassifierNM1(pathname+'/trained_classifierNM1.xml')\n",
    "  er1 = cv2.text.createERFilterNM1(erc1,16,0.00015,0.13,0.2,True,0.1)\n",
    "\n",
    "  erc2 = cv2.text.loadClassifierNM2(pathname+'/trained_classifierNM2.xml')\n",
    "  er2 = cv2.text.createERFilterNM2(erc2,0.5)\n",
    "    # detectRegions: function in MSER class:\n",
    "    # http://docs.opencv.org/3.0.0/d3/d28/classcv_1_1MSER.html\n",
    "    # https://en.wikipedia.org/wiki/Maximally_stable_extremal_regions\n",
    "  regions = cv2.text.detectRegions(channel,er1,er2)\n",
    "  #print regions\n",
    "    # erGrouping:\n",
    "    # Find groups of Extremal Regions that are organized as text blocks\n",
    "  rects = cv2.text.erGrouping(img,channel,[r.tolist() for r in regions])\n",
    "  #rects = cv2.text.erGrouping(img,gray,[x.tolist() for x in regions], cv2.text.ERGROUPING_ORIENTATION_ANY,'../../GSoC2014/opencv_contrib/modules/text/samples/trained_classifier_erGrouping.xml',0.5)\n",
    "  #print rects\n",
    "  #Visualization\n",
    "  for r in range(0,np.shape(rects)[0]):\n",
    "    b.append(rects[r])\n",
    "# consolidate overlapping rectangles\n",
    "c = b\n",
    "h=0\n",
    "while h < len(c):\n",
    "    g=len(c) - 1\n",
    "    while g > h:\n",
    "        if overlap(c[g],c[h]):\n",
    "            c[g] = bigrect(c[g],c[h])\n",
    "            c = np.delete(c,h,axis=0)\n",
    "        g -= 1\n",
    "    h += 1\n",
    "h=0\n",
    "while h < len(c):\n",
    "    g=len(c) - 1\n",
    "    while g > h:\n",
    "        if overlap(c[g],c[h]):\n",
    "            c[g] = bigrect(c[g],c[h])\n",
    "            c = np.delete(c,h,axis=0)\n",
    "        g -= 1\n",
    "    h += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "x=400\n",
    "y=20\n",
    "# # right numberplate\n",
    "# x = 658\n",
    "# y = 369\n",
    "# # back light\n",
    "# x = 533\n",
    "# y = 376\n",
    "\n",
    "# center of mass (cm)\n",
    "rectCM = np.zeros((c.shape[0],2), dtype=int)\n",
    "rectCM[:,0] = c[:,0] + c[:,2]/2\n",
    "rectCM[:,1] = c[:,1] + c[:,3]/2\n",
    "cmDiff = rectCM - np.matlib.repmat(np.array([x,y]),3,1)\n",
    "closestRect = np.argmin(np.hypot(cmDiff[:,0],cmDiff[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print rect\n",
    "rect = c[closestRect,:]\n",
    "cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (0, 0, 0), 2)\n",
    "cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (255, 255, 255), 1)\n",
    "cv2.imwrite('waitrose_boxed.jpg',vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imSeg = img[ rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2] ]\n",
    "cv2.imwrite('textbox.jpg',imSeg)\n",
    "# for i in range(0,len(c)):\n",
    "#     #Visualization\n",
    "#     cv2.imshow(\"Text detection result\", imSeg)\n",
    "#     cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Waitrose'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = tool.image_to_string(\n",
    "    Image.open('textbox.jpg'),\n",
    "    lang=\"eng\",\n",
    "    builder=pyocr.builders.TextBuilder()\n",
    ")\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=Image.open('textbox.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.JpegImagePlugin.JpegImageFile"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imSeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=open('/home/pboord/Downloads/yelp/textbox.jpg', 'rb').read().encode('base64').replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use tool 'Tesseract (sh)'\n",
      "Available languages: Info in bmfCreate: Generating pixa of bitmap fonts from string, osd, eng, equ\n",
      "Will use lang 'Info in bmfCreate: Generating pixa of bitmap fonts from string'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "import pyocr\n",
    "import pyocr.builders\n",
    "\n",
    "tools = pyocr.get_available_tools()\n",
    "if len(tools) == 0:\n",
    "    print(\"No OCR tool found\")\n",
    "    sys.exit(1)\n",
    "# The tools are returned in the recommended order of usage\n",
    "tool = tools[0]\n",
    "print(\"Will use tool '%s'\" % (tool.get_name()))\n",
    "# Ex: Will use tool 'libtesseract'\n",
    "\n",
    "langs = tool.get_available_languages()\n",
    "print(\"Available languages: %s\" % \", \".join(langs))\n",
    "lang = langs[0]\n",
    "print(\"Will use lang '%s'\" % (lang))\n",
    "# Ex: Will use lang 'fra'\n",
    "# Note that languages are NOT sorted in any way. Please refer\n",
    "# to the system locale settings for the default language\n",
    "# to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Waitrose'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = tool.image_to_string(\n",
    "    Image.open('textbox.jpg'),\n",
    "    lang=\"eng\",\n",
    "    builder=pyocr.builders.TextBuilder()\n",
    ")\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Waitrose'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = tool.image_to_string(\n",
    "    Image.fromarray(imSeg),\n",
    "    lang=\"eng\",\n",
    "    builder=pyocr.builders.TextBuilder()\n",
    ")\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_boxes = tool.image_to_string(\n",
    "    Image.open('textbox.jpg'),\n",
    "    lang=\"eng\",\n",
    "    builder=pyocr.builders.WordBoxBuilder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__delslice__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getslice__',\n",
       " '__gt__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setslice__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'append',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'sort']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[method for method in dir(word_boxes) if callable(getattr(word_boxes, method))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info in bmfCreate: Generating pixa of bitmap fonts from string\n",
      "Tesseract Open Source OCR Engine vbd45b3a with Leptonica\n",
      "Warning. Invalid resolution 0 dpi. Using 70 instead.\n"
     ]
    }
   ],
   "source": [
    "!tesseract textbox.jpg out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named google.cloud",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-22090c490785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./im_1.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named google.cloud"
     ]
    }
   ],
   "source": [
    "from google.cloud import vision\n",
    "client = vision.Client()\n",
    "with open('./im_1.jpg', 'rb') as image_file:\n",
    "    image = client.image(content=image_file.read())\n",
    "    texts = image.detect_text()\n",
    "    texts[0].locale\n",
    "    texts[0].description\n",
    "    texts[1].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "/home/travis/miniconda/conda-bld/conda_1485299288502/work/opencv-3.2.0/modules/imgproc/src/color.cpp:9748: error: (-215) scn == 3 || scn == 4 in function cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7805f22e08cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'digits.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Now we split the image to 5000 cells, each 20x20 size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/travis/miniconda/conda-bld/conda_1485299288502/work/opencv-3.2.0/modules/imgproc/src/color.cpp:9748: error: (-215) scn == 3 || scn == 4 in function cvtColor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('digits.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Now we split the image to 5000 cells, each 20x20 size\n",
    "cells = [np.hsplit(row,100) for row in np.vsplit(gray,50)]\n",
    "\n",
    "# Make it into a Numpy array. It size will be (50,100,20,20)\n",
    "x = np.array(cells)\n",
    "\n",
    "# Now we prepare train_data and test_data.\n",
    "train = x[:,:50].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "test = x[:,50:100].reshape(-1,400).astype(np.float32) # Size = (2500,400)\n",
    "\n",
    "# Create labels for train and test data\n",
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k,250)[:,np.newaxis]\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "# Initiate kNN, train the data, then test it with test data for k=1\n",
    "knn = cv2.KNearest()\n",
    "knn.train(train,train_labels)\n",
    "ret,result,neighbours,dist = knn.find_nearest(test,k=5)\n",
    "\n",
    "# Now we check the accuracy of classification\n",
    "# For that, compare the result with test_labels and check which are wrong\n",
    "matches = result==test_labels\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct*100.0/result.size\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
